{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c6b4c0e-f36d-4018-b645-85e7bfc3cc6e",
        "outputId": "b96baa9b-232a-4bf1-9a4e-3853f72bc2b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import argparse\n",
        "import json\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Dense, Input, Dropout, SimpleRNN, Activation, LSTM, Bidirectional, GRU\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda,Concatenate,Dot\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import argparse\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)"
      ],
      "id": "5c6b4c0e-f36d-4018-b645-85e7bfc3cc6e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_yxkFv3uQ6s-",
        "outputId": "10451916-d417-4450-90e3-599375ec780a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "id": "_yxkFv3uQ6s-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNwYsWY8HJoW",
        "outputId": "34f7ef51-5349-4756-e35a-8ceb87c96e68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "uNwYsWY8HJoW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a28c002-8368-4d89-8002-eb487ad35739"
      },
      "outputs": [],
      "source": [
        "f = open('./drive/MyDrive/data/train-v2.0.json','r')\n",
        "data = json.load(f)"
      ],
      "id": "4a28c002-8368-4d89-8002-eb487ad35739"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ed59d1a-1190-4cb5-aae5-0764858ca863"
      },
      "outputs": [],
      "source": [
        "def tokenize(sequence):\n",
        "    tokens = [token.replace(\"``\", '\"').replace(\"''\", '\"').lower() for token in nltk.word_tokenize(sequence)]\n",
        "    return tokens"
      ],
      "id": "6ed59d1a-1190-4cb5-aae5-0764858ca863"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4c31496-8690-400b-88f1-77d25e72df0c"
      },
      "outputs": [],
      "source": [
        "def char_2_word_mapping(context,context_tokens):\n",
        "    w = ''\n",
        "    current_token_idx = 0 # current word loc\n",
        "    mapping = dict()\n",
        "\n",
        "    for char_idx, char in enumerate(context): # step through original characters\n",
        "        if char != ' ' and char != '\\n': # if it's not a space:\n",
        "            w += char # add to accumulator\n",
        "            context_token = context_tokens[current_token_idx] # current word token\n",
        "            if w == context_token: # if the accumulator now matches the current word token\n",
        "                syn_start = char_idx - len(w) + 1 # char loc of the start of this word\n",
        "                for char_loc in range(syn_start, char_idx+1):\n",
        "                    mapping[char_loc] = (w, current_token_idx) # add to mapping\n",
        "                w = '' # reset accumulator\n",
        "                current_token_idx += 1\n",
        "\n",
        "    if current_token_idx != len(context_tokens):\n",
        "        return None\n",
        "    else:\n",
        "        return mapping\n"
      ],
      "id": "e4c31496-8690-400b-88f1-77d25e72df0c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "613bc3c6-f590-4a0f-ad86-bcd952121768"
      },
      "source": [
        "## Preprocessing of Data"
      ],
      "id": "613bc3c6-f590-4a0f-ad86-bcd952121768"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf0b7612-b7e2-48f7-83d5-7c62ffd0d952"
      },
      "outputs": [],
      "source": [
        "def preprocessing(data):\n",
        "    exm = 0\n",
        "    exmpl = []\n",
        "    max_len_context=0\n",
        "    max_len_question=0\n",
        "\n",
        "    for a_id in tqdm(range(len(data['data'])), desc=\"Preprocessing\"):\n",
        "        a_paras = data['data'][a_id]['paragraphs']\n",
        "\n",
        "        for pid in range(len(a_paras)):\n",
        "            context = a_paras[pid]['context']\n",
        "            context = context.replace(\"''\", '\" ')\n",
        "            context = context.replace(\"``\", '\" ')\n",
        "\n",
        "            context_tokens = tokenize(context)\n",
        "\n",
        "            if len(context_tokens)>250:\n",
        "                continue\n",
        "\n",
        "            context = context.lower()\n",
        "\n",
        "            qas = a_paras[pid]['qas']\n",
        "            char2wordloc = char_2_word_mapping(context, context_tokens)\n",
        "\n",
        "            if char2wordloc is None:\n",
        "                continue\n",
        "\n",
        "            if len(context_tokens)>max_len_context:\n",
        "                max_len_context = len(context_tokens)\n",
        "\n",
        "            for q in qas:\n",
        "                question = q['question']\n",
        "                question_tokens = tokenize(question)\n",
        "\n",
        "                if q['is_impossible']==True or len(question_tokens)>30 or ('why' in question_tokens) or ('how' in question_tokens):\n",
        "                    continue\n",
        "\n",
        "                ans_text = (q['answers'][0]['text']).lower()\n",
        "                a_start_char_loc = q['answers'][0]['answer_start']\n",
        "                a_end_char_loc = int(a_start_char_loc) + len(ans_text)\n",
        "                if context[int(a_start_char_loc):a_end_char_loc] != ans_text:\n",
        "                    continue\n",
        "\n",
        "                ans_start_wordloc = char2wordloc[a_start_char_loc][1]\n",
        "                ans_end_wordloc = char2wordloc[a_end_char_loc-1][1]\n",
        "                assert ans_start_wordloc <= ans_end_wordloc\n",
        "\n",
        "                ans_tokens = context_tokens[ans_start_wordloc:ans_end_wordloc+1]\n",
        "                if \"\".join(ans_tokens) != \"\".join(ans_text.split()):\n",
        "                    continue\n",
        "                if len(question_tokens)>max_len_question:\n",
        "                    max_len_question = len(question_tokens)\n",
        "\n",
        "                exmpl.append((' '.join(context_tokens), ' '.join(question_tokens), ' '.join(ans_tokens), ' '.join([str(ans_start_wordloc), str(ans_end_wordloc)])))\n",
        "                exm += 1\n",
        "    print(\"Number Total examples: \"+str(exm))\n",
        "    return exmpl,max_len_context,max_len_question"
      ],
      "id": "bf0b7612-b7e2-48f7-83d5-7c62ffd0d952"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faaf8772-835e-4fd7-b8a8-d4bd54c43199",
        "outputId": "f2026760-4637-44cc-fd33-6bcf0b812781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing: 100%|██████████| 442/442 [00:49<00:00,  8.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number Total examples: 71812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "exmpl,max_len_context,max_len_question = preprocessing(data)"
      ],
      "id": "faaf8772-835e-4fd7-b8a8-d4bd54c43199"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "311ae1f3-173d-48ff-931d-c2051219202c",
        "outputId": "77e64c8f-ba78-4b73-d48f-582d99154bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('beyoncé giselle knowles-carter ( /biːˈjɒnseɪ/ bee-yon-say ) ( born september 4 , 1981 ) is an american singer , songwriter , record producer and actress . born and raised in houston , texas , she performed in various singing and dancing competitions as a child , and rose to fame in the late 1990s as lead singer of r & b girl-group destiny \\'s child . managed by her father , mathew knowles , the group became one of the world \\'s best-selling girl groups of all time . their hiatus saw the release of beyoncé \\'s debut album , dangerously in love ( 2003 ) , which established her as a solo artist worldwide , earned five grammy awards and featured the billboard hot 100 number-one singles \" crazy in love \" and \" baby boy \" .', 'when did beyonce start becoming popular ?', 'in the late 1990s', '50 53')\n",
            "250\n",
            "30\n"
          ]
        }
      ],
      "source": [
        "print(exmpl[0])\n",
        "print(max_len_context)\n",
        "print(max_len_question)"
      ],
      "id": "311ae1f3-173d-48ff-931d-c2051219202c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4892f00-f44c-4673-bab1-0e10e5d505a7"
      },
      "outputs": [],
      "source": [
        "def glove_process():\n",
        "    _pad = b\"<pad>\"\n",
        "    _unk = b\"<unk>\"\n",
        "    _extra_vocab = [_pad, _unk]\n",
        "    padid = 0\n",
        "    unkid = 1\n",
        "    vocab_size = int(4e5)\n",
        "\n",
        "    emd_mat = np.zeros((vocab_size+len(_extra_vocab),100))\n",
        "    word2idx = {}\n",
        "    idx2word = {}\n",
        "\n",
        "    idx = 0\n",
        "\n",
        "    for w in _extra_vocab:\n",
        "        word2idx[w]=idx\n",
        "        idx2word[idx]=w\n",
        "        idx+=1\n",
        "\n",
        "    f = open('./drive/MyDrive/data/glove.6B.100d.txt','r')\n",
        "\n",
        "    for line in tqdm(f, total=vocab_size):\n",
        "        line = line.lstrip().rstrip().split(\" \")\n",
        "        w = line[0]\n",
        "        embedding = list(map(float, line[1:]))\n",
        "        emd_mat[idx, :] = embedding\n",
        "        word2idx[w] = idx\n",
        "        idx2word[idx] = w\n",
        "        idx += 1\n",
        "    return emd_mat, word2idx, idx2word"
      ],
      "id": "a4892f00-f44c-4673-bab1-0e10e5d505a7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df502a40-b95b-434a-b9f9-c9547800bd14",
        "outputId": "94076c02-6c17-4855-d934-7768cd3d7504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400000/400000 [00:14<00:00, 28327.41it/s]\n"
          ]
        }
      ],
      "source": [
        "vocab_size = int(4e5)+2\n",
        "em,word2idx,idx2word = glove_process()"
      ],
      "id": "df502a40-b95b-434a-b9f9-c9547800bd14"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fecae3d-6f6e-4bb3-95a8-c10096a7eef1"
      },
      "outputs": [],
      "source": [
        "def sentences_to_indices(X, word_to_index, max_len):\n",
        "    m = X.shape[0]\n",
        "    X_indices = np.zeros((m,max_len))\n",
        "\n",
        "    for i in range(m):\n",
        "\n",
        "        # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n",
        "        sentence_words = X[i].lower().split()\n",
        "\n",
        "        # Initialize j to 0\n",
        "        j = 0\n",
        "\n",
        "        # Loop over the words of sentence_words\n",
        "        for w in sentence_words:\n",
        "            # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
        "            if w in word_to_index.keys():\n",
        "                X_indices[i, j] = word_to_index[w]\n",
        "            else:\n",
        "                X_indices[i, j] = word_to_index[b\"<unk>\"]\n",
        "            # Increment j to j + 1\n",
        "            j += 1\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return X_indices"
      ],
      "id": "1fecae3d-6f6e-4bb3-95a8-c10096a7eef1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80a4628a-e728-471c-b91f-449a1a348308"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "b_size=64\n",
        "n = math.floor((len(exmpl)/b_size))*b_size\n",
        "m = np.array(exmpl[:n])"
      ],
      "id": "80a4628a-e728-471c-b91f-449a1a348308"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "705831c8-5f12-4fba-8679-9c4f868cc88a"
      },
      "outputs": [],
      "source": [
        "con = sentences_to_indices(m[:,0],word2idx,max_len_context)\n",
        "qe = sentences_to_indices(m[:,1],word2idx,max_len_question)"
      ],
      "id": "705831c8-5f12-4fba-8679-9c4f868cc88a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7fcebbf-fc93-4fd7-ab7e-e426a99a080d"
      },
      "outputs": [],
      "source": [
        "def pretrained_embedding_layer(voc_len,emb_mat):\n",
        "    embedding_layer = Embedding(voc_len, 100,trainable=False)\n",
        "    embedding_layer.build((None,))\n",
        "    embedding_layer.set_weights([emb_mat])\n",
        "\n",
        "    return embedding_layer"
      ],
      "id": "b7fcebbf-fc93-4fd7-ab7e-e426a99a080d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c1691e3-b05a-4d4e-8b47-f18378e34f92"
      },
      "outputs": [],
      "source": [
        "concatenator = Concatenate(axis=2)"
      ],
      "id": "0c1691e3-b05a-4d4e-8b47-f18378e34f92"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75620ae8-1f16-49ae-b600-9b7afc02f88f"
      },
      "outputs": [],
      "source": [
        "def encoder(embedding_context,embedding_question):\n",
        "    H_P = Bidirectional(GRU(150,return_sequences=True))(embedding_context)\n",
        "    H_Q = Bidirectional(GRU(150,return_sequences=True))(embedding_question)\n",
        "    return H_P,H_Q"
      ],
      "id": "75620ae8-1f16-49ae-b600-9b7afc02f88f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzgqzt8RGaf6"
      },
      "outputs": [],
      "source": [
        "def matrix_multiplication(mat, weight):\n",
        "  # [batch_size, seq_len, hidden_size] * [hidden_size, p] = [batch_size, seq_len, p]\n",
        "  mat_shape = mat.get_shape().as_list()  # shape - ijk\n",
        "  weight_shape = weight.get_shape().as_list()  # shape -kl\n",
        "  assert (mat_shape[-1] == weight_shape[0])\n",
        "  mat_reshape = tf.reshape(mat, [-1, mat_shape[-1]])  # [batch_size * n, m]\n",
        "  mul = tf.matmul(mat_reshape, weight)  # [batch_size * n, p]\n",
        "  return tf.reshape(mul, [-1, mat_shape[1], weight_shape[-1]])  # reshape to batch_size, seq_len, p\n"
      ],
      "id": "hzgqzt8RGaf6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlQqA3mMFHhM"
      },
      "outputs": [],
      "source": [
        "def highway_layer(x,size,cb=-1):\n",
        "  W_T = tf.Variable(tf.random.truncated_normal([size, size], stddev=0.1), name=\"weight_transform\")\n",
        "  b_T = tf.Variable(tf.constant(cb, shape=[size],dtype='float32'), name=\"bias_transform\")\n",
        "\n",
        "  W = tf.Variable(tf.random.truncated_normal([size, size], stddev=0.1), name=\"weight\")\n",
        "  b = tf.Variable(tf.constant(0.1, shape=[size],dtype='float32'), name=\"bias\")\n",
        "\n",
        "  T = tf.sigmoid(matrix_multiplication(x, W_T) + b_T, name=\"transform_gate\")\n",
        "  H = tf.nn.relu(matrix_multiplication(x, W) + b, name=\"activation\")\n",
        "\n",
        "  C = tf.subtract(1.0, T, name=\"carry_gate\")\n",
        "\n",
        "  y = tf.add(tf.multiply(H, T), tf.multiply(x, C), \"y\")\n",
        "  return y"
      ],
      "id": "jlQqA3mMFHhM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e4240a3-695e-4edf-a315-a324c48c849a"
      },
      "outputs": [],
      "source": [
        "def basic_attention(H_P,H_Q):\n",
        "    z = tf.matmul(H_P,tf.transpose(H_Q,perm=[0, 2, 1]))\n",
        "    z = tf.nn.softmax(z, 2)\n",
        "    z = tf.matmul(z,H_Q)\n",
        "    concate =  tf.concat([H_P, z], axis=2)\n",
        "    return concate"
      ],
      "id": "2e4240a3-695e-4edf-a315-a324c48c849a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4cba076"
      },
      "outputs": [],
      "source": [
        "def mask_sm(logits,dim):\n",
        "    mask = (logits==0)\n",
        "    mask_exp = (tf.cast(mask, 'float'))*(1e-30)\n",
        "    mask_logits = tf.add(logits,mask_exp)\n",
        "    ans = tf.nn.softmax(mask_logits, dim)\n",
        "    return ans"
      ],
      "id": "a4cba076"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5a22029-5313-4cfb-b0e2-433cac0f15e0"
      },
      "outputs": [],
      "source": [
        "def bidaf_attention(H_P,H_Q):\n",
        "    S_W = tf.Variable(tf.initializers.GlorotUniform()(shape=[3*300]))\n",
        "    c_expand = tf.expand_dims(H_P,2)\n",
        "    q_expand = tf.expand_dims(H_Q,1)\n",
        "    c_pointWise_q = c_expand * q_expand\n",
        "    c_input = tf.tile(c_expand, [1, 1, tf.shape(H_Q)[1], 1])\n",
        "    q_input = tf.tile(q_expand, [1, tf.shape(H_P)[1], 1, 1])\n",
        "    concat_input = tf.concat([c_input, q_input, c_pointWise_q], -1)\n",
        "    similarity=tf.reduce_sum(concat_input * S_W, axis=3)\n",
        "\n",
        "    #c2q_dist = tf.nn.softmax(similarity, 2)\n",
        "    c2q_dist = mask_sm(similarity, 2)\n",
        "\n",
        "    c2q = tf.matmul(c2q_dist, H_Q)\n",
        "    S_max = tf.reduce_max(similarity, axis=2)\n",
        "\n",
        "    #c_dash_dist = tf.nn.softmax(S_max,1)\n",
        "    c_dash_dist = mask_sm(S_max,1)\n",
        "\n",
        "    c_dash_dist_expand = tf.expand_dims(c_dash_dist, 1)\n",
        "    c_dash = tf.matmul(c_dash_dist_expand, H_P)\n",
        "    c_c2q = H_P * c2q\n",
        "    c_c_dash = H_P * c_dash\n",
        "    output = tf.concat([c2q, c_c2q, c_c_dash], axis=2)\n",
        "    ble_rep = tf.concat([H_P, output], axis=2)\n",
        "    concate  = Bidirectional(GRU(150,return_sequences=True))(ble_rep)\n",
        "    return concate"
      ],
      "id": "b5a22029-5313-4cfb-b0e2-433cac0f15e0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a86f3897-0098-4b2d-ad75-6105aa3156a4"
      },
      "outputs": [],
      "source": [
        "def decoder(concate_final):\n",
        "    s = Dense(1,activation=None)(concate_final)\n",
        "    s = tf.squeeze(s, axis=[2])\n",
        "    #s = mask_sm(s,0)\n",
        "\n",
        "    e = Dense(1,activation=None)(concate_final)\n",
        "    e = tf.squeeze(e, axis=[2])\n",
        "    #e = mask_sm(e,0)\n",
        "    return s,e"
      ],
      "id": "a86f3897-0098-4b2d-ad75-6105aa3156a4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a4760e5-9efe-41c6-9b18-3c1a1f981c3b"
      },
      "outputs": [],
      "source": [
        "def modelf(b_size,attention_type=\"basic\"):\n",
        "    context_indices = Input(shape = (max_len_context,),batch_size=b_size)\n",
        "    question_indices = Input(shape = (max_len_question,),batch_size=b_size)\n",
        "\n",
        "    embedding_layer = pretrained_embedding_layer(vocab_size,em)\n",
        "    embedding_context = embedding_layer(context_indices)\n",
        "    embedding_question = embedding_layer(question_indices)\n",
        "\n",
        "    dim = embedding_context.get_shape().as_list()[-1]\n",
        "\n",
        "    for i in range(2):\n",
        "      embedding_context = highway_layer(embedding_context,dim,cb=-1)\n",
        "      embedding_question = highway_layer(embedding_question,dim,cb=-1)\n",
        "    H_P,H_Q = encoder(embedding_context,embedding_question)\n",
        "\n",
        "    if attention_type==\"basic\":\n",
        "        concate = basic_attention(H_P,H_Q)\n",
        "    else:\n",
        "        #Bidef attention\n",
        "        concate = bidaf_attention(H_P,H_Q)\n",
        "\n",
        "    concate_final = Dense(200,activation='relu')(concate)\n",
        "\n",
        "    s,e = decoder(concate_final)\n",
        "\n",
        "    model = Model(inputs=[context_indices,question_indices],outputs=tf.transpose(tf.stack([s,e]),[1, 0, 2]))\n",
        "    return model"
      ],
      "id": "6a4760e5-9efe-41c6-9b18-3c1a1f981c3b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "697044d2-6264-4a23-a747-b42f0cdc4172",
        "outputId": "c00ba46b-3437-4690-bfd5-1af2586576cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul), but are not present in its tracked objects:   <tf.Variable 'weight_transform:0' shape=(100, 100) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add), but are not present in its tracked objects:   <tf.Variable 'bias_transform:0' shape=(100,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul_1), but are not present in its tracked objects:   <tf.Variable 'weight:0' shape=(100, 100) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_1), but are not present in its tracked objects:   <tf.Variable 'bias:0' shape=(100,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul_2), but are not present in its tracked objects:   <tf.Variable 'weight_transform:0' shape=(100, 100) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_2), but are not present in its tracked objects:   <tf.Variable 'bias_transform:0' shape=(100,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul_3), but are not present in its tracked objects:   <tf.Variable 'weight:0' shape=(100, 100) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_3), but are not present in its tracked objects:   <tf.Variable 'bias:0' shape=(100,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul_4), but are not present in its tracked objects:   <tf.Variable 'weight_transform:0' shape=(100, 100) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_4), but are not present in its tracked objects:   <tf.Variable 'bias_transform:0' shape=(100,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul_5), but are not present in its tracked objects:   <tf.Variable 'weight:0' shape=(100, 100) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_5), but are not present in its tracked objects:   <tf.Variable 'bias:0' shape=(100,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul_6), but are not present in its tracked objects:   <tf.Variable 'weight_transform:0' shape=(100, 100) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_6), but are not present in its tracked objects:   <tf.Variable 'bias_transform:0' shape=(100,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul_7), but are not present in its tracked objects:   <tf.Variable 'weight:0' shape=(100, 100) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_7), but are not present in its tracked objects:   <tf.Variable 'bias:0' shape=(100,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_9), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(900,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
          ]
        }
      ],
      "source": [
        "model = modelf(b_size,\"bidef\")"
      ],
      "id": "697044d2-6264-4a23-a747-b42f0cdc4172"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dc7c088-3e25-47c3-b320-4a9fbf04de48",
        "outputId": "8327af36-9211-406a-8193-a1901a11badd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(64, 250)]          0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(64, 30)]           0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          multiple             40000200    ['input_1[0][0]',                \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " tf.reshape (TFOpLambda)        (16000, 100)         0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " tf.reshape_4 (TFOpLambda)      (1920, 100)          0           ['embedding[1][0]']              \n",
            "                                                                                                  \n",
            " tf.reshape_2 (TFOpLambda)      (16000, 100)         0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " tf.linalg.matmul (TFOpLambda)  (16000, 100)         0           ['tf.reshape[0][0]']             \n",
            "                                                                                                  \n",
            " tf.reshape_6 (TFOpLambda)      (1920, 100)          0           ['embedding[1][0]']              \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_2 (TFOpLambda  (1920, 100)         0           ['tf.reshape_4[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_1 (TFOpLambda  (16000, 100)        0           ['tf.reshape_2[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.reshape_1 (TFOpLambda)      (64, 250, 100)       0           ['tf.linalg.matmul[0][0]']       \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_3 (TFOpLambda  (1920, 100)         0           ['tf.reshape_6[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.reshape_5 (TFOpLambda)      (64, 30, 100)        0           ['tf.linalg.matmul_2[0][0]']     \n",
            "                                                                                                  \n",
            " tf.reshape_3 (TFOpLambda)      (64, 250, 100)       0           ['tf.linalg.matmul_1[0][0]']     \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (64, 250, 100)      0           ['tf.reshape_1[0][0]']           \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.reshape_7 (TFOpLambda)      (64, 30, 100)        0           ['tf.linalg.matmul_3[0][0]']     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  (64, 30, 100)       0           ['tf.reshape_5[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (64, 250, 100)      0           ['tf.reshape_3[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.sigmoid (TFOpLambda)   (64, 250, 100)       0           ['tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  (64, 30, 100)       0           ['tf.reshape_7[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_1 (TFOpLambda)  (64, 30, 100)       0           ['tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " tf.nn.relu (TFOpLambda)        (64, 250, 100)       0           ['tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.subtract (TFOpLambda)  (64, 250, 100)       0           ['tf.math.sigmoid[0][0]']        \n",
            "                                                                                                  \n",
            " tf.nn.relu_1 (TFOpLambda)      (64, 30, 100)        0           ['tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.subtract_1 (TFOpLambda  (64, 30, 100)       0           ['tf.math.sigmoid_1[0][0]']      \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLambda)  (64, 250, 100)       0           ['tf.nn.relu[0][0]',             \n",
            "                                                                  'tf.math.sigmoid[0][0]']        \n",
            "                                                                                                  \n",
            " tf.math.multiply_1 (TFOpLambda  (64, 250, 100)      0           ['embedding[0][0]',              \n",
            " )                                                                'tf.math.subtract[0][0]']       \n",
            "                                                                                                  \n",
            " tf.math.multiply_2 (TFOpLambda  (64, 30, 100)       0           ['tf.nn.relu_1[0][0]',           \n",
            " )                                                                'tf.math.sigmoid_1[0][0]']      \n",
            "                                                                                                  \n",
            " tf.math.multiply_3 (TFOpLambda  (64, 30, 100)       0           ['embedding[1][0]',              \n",
            " )                                                                'tf.math.subtract_1[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.add (TFOpLambda)       (64, 250, 100)       0           ['tf.math.multiply[0][0]',       \n",
            "                                                                  'tf.math.multiply_1[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.add_1 (TFOpLambda)     (64, 30, 100)        0           ['tf.math.multiply_2[0][0]',     \n",
            "                                                                  'tf.math.multiply_3[0][0]']     \n",
            "                                                                                                  \n",
            " tf.reshape_8 (TFOpLambda)      (16000, 100)         0           ['tf.math.add[0][0]']            \n",
            "                                                                                                  \n",
            " tf.reshape_12 (TFOpLambda)     (1920, 100)          0           ['tf.math.add_1[0][0]']          \n",
            "                                                                                                  \n",
            " tf.reshape_10 (TFOpLambda)     (16000, 100)         0           ['tf.math.add[0][0]']            \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_4 (TFOpLambda  (16000, 100)        0           ['tf.reshape_8[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.reshape_14 (TFOpLambda)     (1920, 100)          0           ['tf.math.add_1[0][0]']          \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_6 (TFOpLambda  (1920, 100)         0           ['tf.reshape_12[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_5 (TFOpLambda  (16000, 100)        0           ['tf.reshape_10[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.reshape_9 (TFOpLambda)      (64, 250, 100)       0           ['tf.linalg.matmul_4[0][0]']     \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_7 (TFOpLambda  (1920, 100)         0           ['tf.reshape_14[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.reshape_13 (TFOpLambda)     (64, 30, 100)        0           ['tf.linalg.matmul_6[0][0]']     \n",
            "                                                                                                  \n",
            " tf.reshape_11 (TFOpLambda)     (64, 250, 100)       0           ['tf.linalg.matmul_5[0][0]']     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  (64, 250, 100)      0           ['tf.reshape_9[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.reshape_15 (TFOpLambda)     (64, 30, 100)        0           ['tf.linalg.matmul_7[0][0]']     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TFOpLa  (64, 30, 100)       0           ['tf.reshape_13[0][0]']          \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  (64, 250, 100)      0           ['tf.reshape_11[0][0]']          \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_2 (TFOpLambda)  (64, 250, 100)      0           ['tf.__operators__.add_4[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TFOpLa  (64, 30, 100)       0           ['tf.reshape_15[0][0]']          \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_3 (TFOpLambda)  (64, 30, 100)       0           ['tf.__operators__.add_6[0][0]'] \n",
            "                                                                                                  \n",
            " tf.nn.relu_2 (TFOpLambda)      (64, 250, 100)       0           ['tf.__operators__.add_5[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.subtract_2 (TFOpLambda  (64, 250, 100)      0           ['tf.math.sigmoid_2[0][0]']      \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.nn.relu_3 (TFOpLambda)      (64, 30, 100)        0           ['tf.__operators__.add_7[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.subtract_3 (TFOpLambda  (64, 30, 100)       0           ['tf.math.sigmoid_3[0][0]']      \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_4 (TFOpLambda  (64, 250, 100)      0           ['tf.nn.relu_2[0][0]',           \n",
            " )                                                                'tf.math.sigmoid_2[0][0]']      \n",
            "                                                                                                  \n",
            " tf.math.multiply_5 (TFOpLambda  (64, 250, 100)      0           ['tf.math.add[0][0]',            \n",
            " )                                                                'tf.math.subtract_2[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.multiply_6 (TFOpLambda  (64, 30, 100)       0           ['tf.nn.relu_3[0][0]',           \n",
            " )                                                                'tf.math.sigmoid_3[0][0]']      \n",
            "                                                                                                  \n",
            " tf.math.multiply_7 (TFOpLambda  (64, 30, 100)       0           ['tf.math.add_1[0][0]',          \n",
            " )                                                                'tf.math.subtract_3[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.add_2 (TFOpLambda)     (64, 250, 100)       0           ['tf.math.multiply_4[0][0]',     \n",
            "                                                                  'tf.math.multiply_5[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.add_3 (TFOpLambda)     (64, 30, 100)        0           ['tf.math.multiply_6[0][0]',     \n",
            "                                                                  'tf.math.multiply_7[0][0]']     \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (64, 250, 300)       226800      ['tf.math.add_2[0][0]']          \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (64, 30, 300)       226800      ['tf.math.add_3[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape (TFOpLambda  (3,)                0           ['bidirectional_1[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_1 (TFOpLamb  (3,)                0           ['bidirectional[0][0]']          \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.expand_dims (TFOpLambda)    (64, 250, 1, 300)    0           ['bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  ()                  0           ['tf.compat.v1.shape[0][0]']     \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " tf.expand_dims_1 (TFOpLambda)  (64, 1, 30, 300)     0           ['bidirectional_1[0][0]']        \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  ()                  0           ['tf.compat.v1.shape_1[0][0]']   \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.tile (TFOpLambda)           (64, 250, 30, 300)   0           ['tf.expand_dims[0][0]',         \n",
            "                                                                  'tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " tf.tile_1 (TFOpLambda)         (64, 250, 30, 300)   0           ['tf.expand_dims_1[0][0]',       \n",
            "                                                                  'tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_8 (TFOpLambda  (64, 250, 30, 300)  0           ['tf.expand_dims[0][0]',         \n",
            " )                                                                'tf.expand_dims_1[0][0]']       \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (64, 250, 30, 900)   0           ['tf.tile[0][0]',                \n",
            "                                                                  'tf.tile_1[0][0]',              \n",
            "                                                                  'tf.math.multiply_8[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.multiply_9 (TFOpLambda  (64, 250, 30, 900)  0           ['tf.concat[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum (TFOpLambda  (64, 250, 30)       0           ['tf.math.multiply_9[0][0]']     \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.reduce_max (TFOpLambda  (64, 250)           0           ['tf.math.reduce_sum[0][0]']     \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.__operators__.eq_1 (TFOpLam  (64, 250)           0           ['tf.math.reduce_max[0][0]']     \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " tf.__operators__.eq (TFOpLambd  (64, 250, 30)       0           ['tf.math.reduce_sum[0][0]']     \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.cast_1 (TFOpLambda)         (64, 250)            0           ['tf.__operators__.eq_1[0][0]']  \n",
            "                                                                                                  \n",
            " tf.cast (TFOpLambda)           (64, 250, 30)        0           ['tf.__operators__.eq[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_11 (TFOpLambd  (64, 250)           0           ['tf.cast_1[0][0]']              \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_10 (TFOpLambd  (64, 250, 30)       0           ['tf.cast[0][0]']                \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.add_5 (TFOpLambda)     (64, 250)            0           ['tf.math.reduce_max[0][0]',     \n",
            "                                                                  'tf.math.multiply_11[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.add_4 (TFOpLambda)     (64, 250, 30)        0           ['tf.math.reduce_sum[0][0]',     \n",
            "                                                                  'tf.math.multiply_10[0][0]']    \n",
            "                                                                                                  \n",
            " tf.nn.softmax_1 (TFOpLambda)   (64, 250)            0           ['tf.math.add_5[0][0]']          \n",
            "                                                                                                  \n",
            " tf.nn.softmax (TFOpLambda)     (64, 250, 30)        0           ['tf.math.add_4[0][0]']          \n",
            "                                                                                                  \n",
            " tf.expand_dims_2 (TFOpLambda)  (64, 1, 250)         0           ['tf.nn.softmax_1[0][0]']        \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_8 (TFOpLambda  (64, 250, 300)      0           ['tf.nn.softmax[0][0]',          \n",
            " )                                                                'bidirectional_1[0][0]']        \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_9 (TFOpLambda  (64, 1, 300)        0           ['tf.expand_dims_2[0][0]',       \n",
            " )                                                                'bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " tf.math.multiply_12 (TFOpLambd  (64, 250, 300)      0           ['bidirectional[0][0]',          \n",
            " a)                                                               'tf.linalg.matmul_8[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.multiply_13 (TFOpLambd  (64, 250, 300)      0           ['bidirectional[0][0]',          \n",
            " a)                                                               'tf.linalg.matmul_9[0][0]']     \n",
            "                                                                                                  \n",
            " tf.concat_1 (TFOpLambda)       (64, 250, 900)       0           ['tf.linalg.matmul_8[0][0]',     \n",
            "                                                                  'tf.math.multiply_12[0][0]',    \n",
            "                                                                  'tf.math.multiply_13[0][0]']    \n",
            "                                                                                                  \n",
            " tf.concat_2 (TFOpLambda)       (64, 250, 1200)      0           ['bidirectional[0][0]',          \n",
            "                                                                  'tf.concat_1[0][0]']            \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirectional  (64, 250, 300)      1216800     ['tf.concat_2[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (64, 250, 200)       60200       ['bidirectional_2[0][0]']        \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (64, 250, 1)         201         ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (64, 250, 1)         201         ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " tf.compat.v1.squeeze (TFOpLamb  (64, 250)           0           ['dense_1[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.compat.v1.squeeze_1 (TFOpLa  (64, 250)           0           ['dense_2[0][0]']                \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.stack (TFOpLambda)          (2, 64, 250)         0           ['tf.compat.v1.squeeze[0][0]',   \n",
            "                                                                  'tf.compat.v1.squeeze_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose (TFOpLa  (64, 2, 250)        0           ['tf.stack[0][0]']               \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 41,731,202\n",
            "Trainable params: 1,731,002\n",
            "Non-trainable params: 40,000,200\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ],
      "id": "0dc7c088-3e25-47c3-b320-4a9fbf04de48"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "633b7784-0e9b-44ac-9e44-7ab61922a97f"
      },
      "outputs": [],
      "source": [
        "def custom_loss(y_true,y_pred):\n",
        "    loss_start = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_pred[0,:], labels=y_true[0,:])\n",
        "    loss_start_m = tf.reduce_mean(loss_start)\n",
        "    loss_end = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_pred[1,:], labels=y_true[1,:])\n",
        "    loss_end_m = tf.reduce_mean(loss_end)\n",
        "    loss = loss_start_m + loss_end_m\n",
        "    return loss"
      ],
      "id": "633b7784-0e9b-44ac-9e44-7ab61922a97f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "599b563c-148b-4937-b7f6-342a9ac85c2b"
      },
      "outputs": [],
      "source": [
        "#model.load_weights('./model/model_with_bidef_attention_p'+str(max_len_context)+'_q'+str(max_len_question))\n",
        "opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999,clipvalue=5.0)\n",
        "model.compile(loss = custom_loss, optimizer = opt, metrics = ['accuracy'])"
      ],
      "id": "599b563c-148b-4937-b7f6-342a9ac85c2b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3028396-69c9-4717-839e-bbca75c2bd37"
      },
      "outputs": [],
      "source": [
        "def op(y):\n",
        "    l = []\n",
        "    for i in range(0,len(y)):\n",
        "        t=[]\n",
        "        for w in y[i].split():\n",
        "            t.append(int(w))\n",
        "        l.append(t)\n",
        "    return l"
      ],
      "id": "d3028396-69c9-4717-839e-bbca75c2bd37"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69305319-a091-4486-9717-d2e21b918d23",
        "outputId": "1c89108d-71e3-410b-fdfe-d1a230c463e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing: 100%|██████████| 35/35 [00:03<00:00, 10.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number Total examples: 4820\n"
          ]
        }
      ],
      "source": [
        "f = open('./drive/MyDrive/data/dev-v2.0.json','r')\n",
        "val_data = json.load(f)\n",
        "val_exmpl,val_max_len_context,val_max_len_question = preprocessing(val_data)\n",
        "val_m = np.array(val_exmpl[:])\n",
        "val_con = sentences_to_indices(val_m[:,0],word2idx,max_len_context)\n",
        "val_qe = sentences_to_indices(val_m[:,1],word2idx,max_len_question)\n",
        "y1 = np.array(op(val_m[:,3]))"
      ],
      "id": "69305319-a091-4486-9717-d2e21b918d23"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "d97750ab-17b1-4b8d-b291-62fbd806a1c2",
        "outputId": "b691424c-e0ed-4016-ed0f-0844c10e32ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            " 148/1122 [==>...........................] - ETA: 13:29 - loss: 8.8944 - accuracy: 0.0520"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-c043eb11ad1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_con\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4800\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_qe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4800\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4800\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "y = np.array(op(m[:,3]))\n",
        "h = model.fit([con,qe],y,epochs=5,batch_size=b_size,validation_data=([val_con[:4800],val_qe[:4800]],y1[:4800]))"
      ],
      "id": "d97750ab-17b1-4b8d-b291-62fbd806a1c2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "10c29910-0fe4-4eec-bc94-f5338df193c9",
        "outputId": "88b7cab2-428e-4ae7-c33a-4f7d03b6e553"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc.')\n",
        "plt.title('Plot of accuracy')\n",
        "x = range(0,5)\n",
        "y1 = h.history['accuracy']\n",
        "y2 = h.history['val_accuracy']\n",
        "plt.plot(x,y1)\n",
        "plt.plot(x,y2)\n",
        "plt.savefig('acc_plot.png')"
      ],
      "id": "10c29910-0fe4-4eec-bc94-f5338df193c9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "38fdcd76",
        "outputId": "c644d7ee-f219-4694-fd1b-b48137d44d22"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3gVVfrA8e+bXkkoAeklIFWKRKpSROwiKgooCAgiYll1f+rqquu67q5tV7EAIoIUBZQmsoIFBVSkhCJFQJMgvYQWCCSQ8v7+mIuEmIQAuSW57+d57sO9M2dm3ozeee85M+ccUVWMMcb4rwBvB2CMMca7LBEYY4yfs0RgjDF+zhKBMcb4OUsExhjj5ywRGGOMn7NEYPyGiCwUkSEeOtb9IrJXRNJFpGK+dXVEREUkyBOxGHM2lghMmSIiv4lIhusCvFdEPhCRqHPcxwVdqEUkGPgvcLWqRqnqgfPZjzGeYonAlEU3qWoUcCmQADzj4eNXAcKADR4+rjHnxRKBKbNUdScwD2iWf52IBIjIMyKyVUT2ichEEYlxrV7s+vewq2bRvoDtQ0XkDRHZ5Xq94Vp2MbA5z/bfnC1OEakmInNE5KCIJInIvXnWtRGRRBE54qrh/Ne1PExEJovIARE5LCIrRKTKuZ0hYxyWCEyZJSI1geuB1QWsHuh6dQXqAVHA2651nVz/xrqadn4sYPu/Au2AlkALoA3wjKr+AjTNs/2VxQh1KrADqAb0Av4lIqe2GwGMUNVyQDzwsWv5ACAGqAlUBIYBGcU4ljF/YInAlEWzReQw8D2wCPhXAWXuAv6rqimqmg48BfQ5h/sCdwEvqOo+VU0F/g70P9dAXcmqI/Ckqmaq6hpgLHC3q0gWUF9EKqlquqouzbO8IlBfVXNUdaWqHjnX4xsDlghM2dRTVWNVtbaqDlfVgn4pVwO25vm8FQjCad8vjoK2r3YesVYDDqrq0Xz7qu56Pxi4GNjkav650bV8EvAFMNXVNPWK6ya1MefMEoHxV7uA2nk+1wKygb1AcYbkLWj7XecZRwURic63r50AqvqrqvYFKgMvA9NFJFJVs1T176raBOgA3MjpWoQx58QSgfFXU4BHRaSu6/HSfwHTVDUbSAVyce4dFLX9MyISJyKVgOeAyecahKpuB5YA/3bdAG6OUwuYDCAi/UQkTlVzgcOuzXJFpKuIXCIigcARnKai3HM9vjFgicD4r3E4zSuLgS1AJvAQgKoeB/4J/OB6IqddAdu/CCQCa4F1wCrXsvPRF6iDUzuYBfxNVb92rbsW2CAi6Tg3jvu4mrouAqbjJIGNOPdCJp3n8Y2fE5uYxhhj/JvVCIwxxs9ZIjDGGD9nicAYY/ycJQJjjPFzpW4Y3EqVKmmdOnW8HYYxxpQqK1eu3K+qcQWtK3WJoE6dOiQmJno7DGOMKVVEZGth66xpyBhj/JwlAmOM8XOWCIwxxs9ZIjDGGD9nicAYY/ycJQJjjPFzlgiMMcbPuTURiMijIrJBRNaLyBQRCcu3/jER+VlE1orIAhGpXdi+LlTq0RM8P2cDJ7NtyHZjjMnLbYlARKoDDwMJqtoMCAT65Cu22rW+Oc7Y6q+4K57lWw7ywZLfeHz6T+Tm2tDbxhhzirubhoKAcNeE4BHkm8pPVb91TQICsBSo4a5Abmhelcevacina3bx8heb3HUYY4wpddw2xISq7hSR14BtQAbwpap+WcQmg4F5Ba0QkaHAUIBatWqdd0zDu8SzOy2DdxelUC0mnAEd6pz3vowxpqxwZ9NQeeBmoC5QDYgUkX6FlO0HJACvFrReVceoaoKqJsTFFThmUnFj4u89mtG9SRWe/2wD89fvPu99GWNMWeHOpqGrgC2qmqqqWcBMoEP+QiJyFfBXoIeqnnBjPHB0D4EBwpt9WtGyZiwPT13Dit8OuvWQxhjj69yZCLYB7UQkQkQE6IYzyfbvRKQV8C5OEtjnxlhg/QwY0RK2fEd4SCDvD7iMGrHhDJmQSNK+o249tDHG+DK3JQJVXYbzJNAqYJ3rWGNE5AUR6eEq9ioQBXwiImtEZI674qFuFyhfG6b0gZ2rqBAZwoR72hAcGMCAcSvYdyTTbYc2xhhfJqql61HKhIQEPe/5CI7sgnHXwIl0GDQPKjdi3Y40eo/5kToVI5l2Xzuiw4JLNmBjjPEBIrJSVRMKWudfPYvLVYO7P4XAYJjUEw79xiU1Yhh516Vs3nuU4R+usg5nxhi/41+JAKBCPeg/C7IyYGJPOLqHLg0r89Ktl/Ddr/v5y4y1lLZakjHGXAj/SwQAVZpCvxmQvg8m3QLHD3J7Qk0e634xM1fv5NUvNns7QmOM8Rj/TAQANRKg70dwIAk+vB1OpPPQlfXp26YWIxcmM2lpodN7GmNMmeK/iQCgXhfoNR52rYapdyLZJ/jHzU25qnFl/vbper7csMfbERpjjNv5dyIAaHwj3PwObFkEMwYTRC5v9m3FJTVieWjKalZuPeTtCI0xxq0sEQC07AvXvQKb5sKcB4kICmDcgASqxoQxZMIKUlLTvR2hMca4jSWCU9reB13/Cj9Ngfl/oaKrw1mACAPGL2ffUetwZowpmywR5NXpcWj/ICx/Fxb+m9oVIxk38DL2Hz3JPR+sIP1EtrcjNMaYEmeJIC8RuPpFaNUPFr0MP75Di5qxvHNXKzbudjqcZeVYhzNjTNliiSA/EbjpTWhyM3zxNKyaxJWNqvCvW5qx+JdUnpq5zjqcGWPKFLdNTFOqBQTCre/BiaPw2cMQGk3vy3qy63AmIxb8SrWYMB67uqG3ozTGmBJhiaAwQaHQe7LT83jGEAiN4pGrurEnLZM3v0niophw7mx7/rOlGWOMr7CmoaKERMKdH0NcI5jWH9m+nBdvaUaXhnE8M3sdCzbu9XaExhhzwSwRnE14LPSfCdFV4cPbCU7dwDt3XkrTajE88NEqVm+zDmfGmNLNrYlARB4VkQ0isl5EpohIWL71oSIyTUSSRGSZiNRxZzznLaqyM3x1aBRMuoXIo78xbuBlVI4OY/CERLbsP+btCI0x5ry5c/L66sDDQIKqNgMCgT75ig0GDqlqfeB14GV3xXPBYmtC/9mgCpN6EpebyoR72gAwcPxy9qe7d7plY4xxF3c3DQUB4SISBEQAu/KtvxmY4Ho/Hejmmt/YN8Vd7DQTZabBxJ7UDTvO+wMS2Hskk8EfrOD4SetwZowpfdw5Z/FO4DWcSex3A2mq+mW+YtWB7a7y2UAaUDH/vkRkqIgkikhiamqqu0Iunqot4M5pkLYDJt9Kq8oBvN33UtbtTOOBD1eRbR3OjDGljDubhsrj/OKvC1QDIkWk3/nsS1XHqGqCqibExcWVZJjnp3YH6D0J9v0MH/XmqvrR/KNnM77dnMozs9dbhzNjTKnizqahq4AtqpqqqlnATKBDvjI7gZoAruajGOCAG2MqOQ26O53Oti2Fj+/mrtZVebBrfaau2M6bC5K8HZ0xxhSbOxPBNqCdiES42v27ARvzlZkDDHC97wV8o6Xp53SzW+GmNyDpK5g1lD9fFc9tl9bg9a9/YdqKbd6OzhhjisVtPYtVdZmITAdWAdnAamCMiLwAJKrqHOB9YJKIJAEH+eNTRb6v9UDIPAJfPYuEluOlW18nNf0ET89aT+XoMLo2quztCI0xpkhSmn6AAyQkJGhiYqK3w/ijBS/Ad/+BDg+T3uk5+ry3lOR9x5h2Xzua14j1dnTGGD8nIitVNaGgddazuKRc+SxcNgSWvEnUijcZN/AyKkaFcM8HK9h24Li3ozPGmEJZIigpInDdq3DJHbDgBSpvnMSEe9qQnasMGL+cA9bhzBjjoywRlKSAAOg5Ei6+Dj7/P+J3f877AxLYdTiDwRMSyTiZ4+0IjTHmDywRlLTAYLj9A6hzBcwaRuvMZbzZtxVrdxzmoSnW4cwY43ssEbhDcBj0neL0Qv54ANdE/MLfezTl6437eG7OButwZozxKZYI3CU0GvrNgAp1YUpf+tc6wP1d4vlo2Tbe+dY6nBljfIclAneKqOCMWBpRESbfxhOtcrmlVXVe+/IXpq/c4e3ojDEGsETgfuWqOnMZBIYik27h5SvLcXn9SvxlxloW/+LlAfSMMQZLBJ5RoS70nwXZmYR8dAuje1ajQZVo7p+8kvU707wdnTHGz1ki8JQqTaDfTDi2n6hptzOhTzyxESEMHL+C7Qetw5kxxnssEXhSjdbQ5yM4mELlOf2Y2K8xWTm5DBi/nEPHTno7OmOMn7JE4Gn1OsPt42HXGuIXDOX9uy5hx6EMBk9YQWaWdTgzxnieJQJvaHQD9BwFWxaTsOLPvHl7M1ZvP8zDU1aTk2t9DIwxnmWJwFta9HbGJtr8P65NfpHnbmjElz/v5e+fWYczY4xnuW0+AlMMbYdCZhp8+yKD2pRj9xWDGPPdFqrGhHN/l3hvR2eM8RPunLO4oYisyfM6IiKP5CsTIyKfichPIrJBRAa5Kx6f1en/oP2DsHwMT4XNpEeLarw8fxMzV1mHM2OMZ7hzhrLNQEsAEQnEmZ94Vr5iDwA/q+pNIhIHbBaRD1XVfx6hEYGrX4TMNOS7V/nvVeVIPdqGJ6avpXJ0GJc3qOTtCI0xZZyn7hF0A5JVdWu+5QpEu+Y0jsKZrjLbQzH5DhG4aQQ06UnQ188yrsVG6leOYtjklWzYZR3OjDHu5alE0AeYUsDyt4HGwC5gHfAnVf3DOM0iMlREEkUkMTW1jA7LEBAIt74H8d0In/8YUzruITosiEHjV7DjkHU4M8a4j9sTgYiEAD2ATwpYfQ2wBqiG04z0toiUy19IVceoaoKqJsTFxbk1Xq8KCoHek6BGG8rPG84nVx0nIyuHgeNXcPi4/7SWGWM8yxM1guuAVaq6t4B1g4CZ6kgCtgCNPBCT7wqJhDunQeVG1PjiXqZcC9sOHOfeiYnW4cwY4xaeSAR9KbhZCGAbzv0DRKQK0BBI8UBMvi08FvrNgpjqNPv2Xt67OoQVvx3i0WlrrMOZMabEuTURiEgk0B2YmWfZMBEZ5vr4D6CDiKwDFgBPqup+d8ZUakTFOXMZhEbTedlQXukawbz1e/jH3J+tw5kxpkS5tUOZqh4DKuZbNjrP+13A1e6MoVSLrQl3z4Zx13LHhgfZfdlbvL7kN6rFhjG0k3U4M8aUDBtiwtdVagD9Z8KJIzy863F6NwnjX59v4tM1O70dmTGmjLBEUBpUbQF3foyk7eTfx/5Gl9oh/N8nP7Ek2VrRjDEXzhJBaVG7PfSeTEDqJsYGvUqjikHcN3Elm/Yc8XZkxphSzhJBadLgKrjtPYJ2reCT8iMpF5LLwHEr2HU4w9uRGWNKMUsEpU3TW+CmEYRt/ZZ5NSeTceIkA8cvJy0jy9uRGWNKKUsEpdGld8PVL1IuZS5fNpjJlv3pDJ2YyIls63BmjDl3lghKqw4PQafHqZL0MfMaf8myLQd47OOfyLUOZ8aYc2QT05RmXf8KmWnUXz6GjxtHcMfay6laLoxnbmzi7ciMMaWIJYLSTASufRky02izdiTvNAjnge+hamw4gy+v6+3ojDGlhCWC0i4gAG5+B04c5YbN/2Fvraf4x/+gSrlQbmxezdvRGWNKAbtHUBYEBkOv8VDnCgalvsKwKpt5bNpPLE054O3IjDGlgCWCsiI4DPpOQaq15ImjL3FTTBJDJybyy96j3o7MGOPjLBGUJaHRcNd0pEI9Xs36N5cGpjBg3HL2pGV6OzJjjA+zRFDWRFSA/rMIiIpjbNBLVMlMYeD45RzJtA5nxpiCWSIoi8pVhf6zCQoOY1rEK5zYl8ywSSs5mf2H6aCNMcYSQZlVoS7cPZtQspgb+xpJyUk8Pt06nBlj/shtiUBEGorImjyvIyLySAHlurjWbxCRRe6Kxy9Vbgx3zSAy+zDzKvyXRWs28/L8Td6OyhjjY9yWCFR1s6q2VNWWQGvgODArbxkRiQVGAj1UtSlwu7vi8Vs1WkPfKVQ4sYO5Fd5g8uINfPDDFm9HZYzxIZ5qGuoGJKvq1nzL7wRmquo2AFXd56F4/EvdTsjtH1A94xdmxL7Fv+euYd663d6OyhjjIzyVCPoAUwpYfjFQXkQWishKEbm7oI1FZKiIJIpIYmpqqlsDLbMaXY/0HEWjzDVMih7Nn6clsuK3g96OyhjjA9yeCEQkBOgBfFLA6iCcZqMbgGuAZ0Xk4vyFVHWMqiaoakJcXJxb4y3TWvSG61+jzcmljAgby70fLCdpn3U4M8bfeaJGcB2wSlX3FrBuB/CFqh5T1f3AYqCFB2LyX23uhSufoXv2Qp6W8Qx4fzl7j1iHM2P8mScSQV8KbhYC+BS4XESCRCQCaAts9EBM/u2K/4MOD3GHzufuzEkMHL+Co9bhzBi/5dbRR0UkEugO3Jdn2TAAVR2tqhtFZD6wFsgFxqrqenfGZHCGr+7+D8hM475VEzmYGsH9k0MYN/AyQoKsa4kx/kZUS1cHo4SEBE1MTPR2GGVDbg5Mvwd+ns2TWfeS1bwf/7mjBSLi7ciMMSVMRFaqakJB6+znnz8LCIRb34P6V/FS8FhO/DSDV7/Y7O2ojDEeZonA3wWFwB2ToFY7RoSOZMPimUxamr+7hzGmLLNEYCAkArlzGoFVmjAm9A0+mzOdLzbs8XZUxhgPsURgHGExSL+ZBJevwfjQ1xg1ZSYrt1qHM2P8gSUCc1pUHAED5hAWVYHxQS/xwgefsn5nmrejMsa4mSUCc6aYGgQO+JRy4cG8qy/y7Ogp1kxkTBlnicD8UaX6BN49i7jIAD4JfJoNU/7Ke99uorQ9amyMKR5LBKZgVZsT+MAypNmtPBY0nfbf9uaND2fbLGfGlEGWCEzhIioQ2GssuXdMom7oER74dTCzRjxCWnqGtyMzxpQgSwTmrAKa9CDykUT2Vr+a3kcnsPu/l7Nz8ypvh2WMKSGWCEzxRFak5tCp/Nr5bark7iVuSne2zfkn5GR7OzJjzAUqViIQkQgReVZE3nN9biAiN7o3NOOLGnTtT/rgH1gadBm1Vr3Cgbe6Quov3g7LGHMBilsjGA+cANq7Pu8EXnRLRMbn1axZmxaPzuGtCk8RcCiF7JEdyf3hTWcQO2NMqVPcRBCvqq8AWQCqehywISr9WExkCMMeeIKRTT7km+xLCPjqWXLGXQv7k7wdmjHmHBU3EZwUkXBAAUQkHqeGYPxYcGAAT9/RmW3d3+PRrOFk7NyAjr4clo6CXHvM1JjSoriJ4G/AfKCmiHwILACeKGoDEWkoImvyvI6IyCOFlL1MRLJFpNc5RW+8TkQY0ime6+96hBtyXmNJbhOY/xf44AY4mOLt8IwxxVDsiWlEpCLQDqdJaKlrjuHibhuIc1+hrapuLWDdV0AmME5Vpxe1L5uYxnet35nGkA9W0O3E1zwfOplgcqD7C5AwGALsATVjvOmCJ6YRkY5Apqr+D4gFnhaR2ucQQzcgOX8ScHkImAHsO4f9GR/UrHoMnz50OWvjbqRz+r/YXq4VfP5/MLEHHLI5DozxVcX9mTYKOC4iLYDHgGRg4jkcpw8FTGAvItWBW1z7L5SIDBWRRBFJTE1NPYfDGk+rUi6Mafe145ImTbhi53Bm1vgLumsNjOoAiePAxisyxucUNxFkq9OGdDPwjqq+A0QXZ0MRCQF6AJ8UsPoN4ElVLfLOoqqOUdUEVU2Ii4srZsjGWyJCghh1V2uGda7PY0nNebTiKLKqtoa5j8KknnB4m7dDNMbkUdxEcFREngL6A/8TkQAguJjbXgesUtW9BaxLAKaKyG9AL2CkiPQs5n6NDwsIEP5yXSNeua05c7cGct3BxzjY9WXYvgJGdoCVE6x2YIyPKG4i6I3zuOg9qroHqAG8Wsxt+1JAsxCAqtZV1TqqWgeYDgxX1dnF3K8pBe64rCaTBrclNf0kVy2OZ22PeVCtJXz2MEy+DdJ2ejtEY/xesRKB6+L/IRDjGloiU1XPeo9ARCKB7sDMPMuGiciw84zXlELt4ysya3gHyoUF0WvqLmY3HwXXvwbbfoSR7WH1h1Y7MMaLivX4qIjcgVMDWIjz+OgVwONne9TTHezx0dLr0LGTDJu8kmVbDvJwtwY8emkQMudB2PoDNLgGbhoB5ap6O0xjyqQLfnwU+CtwmaoOUNW7gTbAsyUVoPEP5SNDmDS4Lb1a1+DNBb/y8JdpZN71KVz7MmxZDCPbwk9TrXZgjIcVNxEEqGre5/wPnMO2xvwuJCiAV3s154lrG/LZT7voO3Y5qU0Hwf0/QFwjmHUfTL0Tjhb0bIExxh2KezGfLyJfiMhAERkI/A/43H1hmbJMRBjepT6j7rqUjbuP0POdH9icVRkGzYOr/wnJ3zi1g3XTrXZgjAcU92bx48AYoLnrNUZVn3RnYKbsu+6Sqnx8X3tO5uRy26glLPz1AHR4EO77DirEw4zB8HF/SLdOhMa4U7HHGvIVdrO47Nl1OIPBExLZvOcIz/doyt3t6zhzGyx5C779J4RGww3/gaa3eDtUY0qt875ZLCJHXaOG5n8dFZEj7gnX+JtqseFMH9aerg0r89ynG3h+zgayVeDyR5zaQWwt+GQgfDIIjh3wdrjGlDlFJgJVjVbVcgW8olW1nKeCNGVfZGgQY+5OYPDldflgyW8MmZjI0cwsqNwIBn8NVz4LGz9z7h1s/Mzb4RpTptiTP8ZnBAYIz97YhH/e0ozvft1Pr1E/suPQcQgMgk7/B/ctgnLVYFo/mDEEjh/0dsjGlAmWCIzPuattbT4YdBm70jLo+c4SVm875Kyo0hSGLICuf4UNs2BkO9hkD68Zc6EsERifdEWDOGYN70B4SAB9xixl7tpdzorAYOj8BNz7LURWhql9YdYwyDjk3YCNKcUsERifVb9yNLOHd6R5jRge/Gg1by34ld+fcqvaHO79Bjo/CWs/dsYs+uVL7wZsTCllicD4tIpRoUwe0pZbWlXnP1/9wp8//okT2TnOyqAQ6Po03LsAwsvDR7fD7AcgM827QRtTylgiMD4vNCiQ/97Rgj93v5iZq3fSb+wyDh47ebpAtVYwdCFc8Wf46SOndpD0tbfCNabUsURgSgUR4aFuDXj7zlas3ZFGz3d+IGlf+ukCQaHQ7TkY8jWERDlzHcx5GDKtu4sxZ2OJwJQqNzavxtSh7Th+MptbRv7A97/uP7NA9dZw32Lo+CdYPcmZKzlloVdiNaa0cFsiEJGGIrImz+uIiDySr8xdIrJWRNaJyBIRaeGueEzZ0apWeWY/0JFqMeEMGL+cj5blmwM5OAy6vwD3fOHUFCbeDHMfgxPpBe/QGD/ntkSgqptVtaWqtgRaA8eBWfmKbQE6q+olwD9wBrYz5qxqlI9g+v3tuaJBJZ6etY4X5/5MTm6+cbNqtoFh30P7ByFxnFM72PKddwI2xod5qmmoG5CsqlvzLlTVJap66gHwpThzIRtTLNFhwYy9O4GBHeow9vst3DcpkWMnss8sFBwO1/wT7pkPAYEw4Ub4/Ak4ecw7QRvjgzyVCPpQyAT2eQwG5hW0QkSGikiiiCSmptqQxOa0oMAAnu/RlBdubso3m/bRa/SP7Dqc8ceCtdrBsB+g7f2w/F0Y1RG2LvF8wMb4ILcPQy0iIcAuoKmqFjjtlIh0BUYCl6tqkcNL2jDUpjALN+/jwY9WExESyNgBCTSvEVtwwd++h08fgENbod1wuPIZCInwbLDGeFhJzFl8Ia4DVhWRBJoDY4Gbz5YEjClKl4aVmXF/B4IDA7jj3R+Zv353wQXrXO7UDi4bAkvfgXevgO3LPRusMT7EE4mgL4U0C4lILWAm0F9Vf/FALKaMa3hRNLMf6EjjquUYNnkVIxcmUWCtNzQKbngN7p4D2Sdh3DXw5bOQlen5oI3xMrcmAhGJBLrjXOxPLRsmIsNcH58DKgIjXY+YWpuPuWBx0aFMubcdN7WoxivzN/PE9LWczM4tuHC9zjB8CbQeCEvedGoHO+x/Q+NfbKpKU2apKq9//StvLviVtnUrMLpfa8pHhhS+QfI38OlDcHSX0yGty1NOPwRjygBv3yMwxitEhMe6X8wbvVuyetthbh21hJTUIjqVxV/p1A5a9YPvX4d3O8POVZ4L2BgvsURgyryerarz0b1tScvI4paRS/gxuYhnEsJioMdbcNd0ZxTTsVfBNy869xGMKaMsERi/kFCnArOHdyQuOpT+7y/j4xXbi96gQXcY/iO06AOLX4X3usLunzwTrDEeZvcIjF9Jy8jiwY9W8d2v+7mvcz2evKYRAQFS9Eab58Nnf4Lj+6HT485w14HBngm4NFCFrAxnlriMQ5BxMM/7fK/jed6fOALVL4VmvaDxTRBRwdt/SZlW1D0CSwTG72Tl5PL8nA18uGwb1zStwuu9WxIRElT0RscPwvy/wNppcFFz6DkKLmrmmYA9RdUZeuMPF/D8F/bDrot6nuU5Jwrfb2AIhFdwJg8KL+9c8MNjISjMuUF/MAUCgqF+NycpNLzOebzXlChLBMbko6qM++E3XvzfzzSrFsPYAQlUKRd29g03zoW5jzgXwy5PQsdHIfAsScTTVOHE0UJ+lR88fSE/45e666Kem1X4foPCT1/Mw8tDRPkzP5/xynPhDw4HKaTWpQq718C66bBhFhzZ6Ryn4bVOUqh/lTOarLlglgiMKcSCjXt5aMpqyoUFM3ZAAs2qx5x9o2MHYN7jsH4GVG0Jt4yGyo1LPjhVp/nkeEFNLYeLboLJzS58v8GReS7YsXl+pRd1UY91LujulJsL25c6SeHn2XD8AISWc5qNmt0GdTv7XtItRSwRGFOEn3cdYfCEFaRlZDGiTyu6N6lSzA0/dc1zcMSZO7n9QwVfqHJz4URawe3kZ2uC0ZzCjx8SfebFvLgX9NLQNyInG7YshHUzYNNc5xxHVIKmPZ2kULMdBNizLufCEoExZ7HvSCZDJiaybmcaT1/XmCFX1EUKa87I69h++N9jTlKo2hIqXVzARf0wUMT3LDTmzIv5WS/qrgu6v9ywzsqEpK+cGtjm+ZCdAeVqQLNbnKRQtWXhTU/md5YIjCmGjJM5PPbxGuat30PfNrV44eamBAcW81fn+pnwzT+c5pxiX9DLQ1isNXecixNHYfM8JwxPsacAABNTSURBVCkkfe00gVWIh0t6OUkhrqG3I/RZlgiMKabcXOW1LzczcmEyHetXZOSdrYmJ8JNf3qXN8YOw8TNYP90185xClUug2a1OUihf29sR+hRLBMaco08St/P0rHXUqhDBuIGXUbtipLdDMkU5ugc2zHaSwo4VzrIabZyE0PQWiC7mfZ8yzBKBMedhacoBhk1eiQDv9k+gTV3r8FQqHPrNaapbPwP2rgcJcOagaNYLmvRwmuT8kCUCY87Tlv3HGPzBCnYcyuCl2y7h1kttWu1SZd8mJyGsn+73HdcsERhzAdKOZ3H/hytZknyAB7vW57HuF599WArjW87Wca1B99LxWO0F8EoiEJGGwLQ8i+oBz6nqG3nKCDACuB44DgxU1SLH/bVEYLwhKyeXZ2evZ+qK7dzQvCr/ub0FYcGB3g7LnI8CO67FQOMby3THNa/XCEQkENgJtFXVrXmWXw88hJMI2gIjVLVtUfuyRGC8RVV577sU/j1vE81rxPLe3a2pHG3DH5RqRXZc6wU125aZjmu+kAiuBv6mqh3zLX8XWKiqU1yfNwNdVLWQWcctERjv+2LDHh6ZuoYKkSG8PzCBRheV83ZIpiSc6ri2bjr8Mh+yM8tUxzVfmKGsDwVPYF8dyDsw/A7XsjOIyFARSRSRxNTUVDeFaEzxXNP0Ij4Z1p7s3FxuG7mEbzft83ZIpiQEhznjGt0xAR5Pglvfc0aYXToKxnSBt1rDt/+C1M3ejrTEub1GICIhwC6gqaruzbduLvCSqn7v+rwAeFJVC/3JbzUC4yv2pGUyeMIKNu4+wnM3NmFgx7reDsm4Q2Ed1y65DZreWmo6rnm7RnAdsCp/EnDZCdTM87mGa5kxPu+imDA+GdaeqxpX4fnPfua5T9dzIruIQeJM6RRRAVoPgAGfwZ83wbUvO7WHr5+HEc1hbHdYOhqOFnSJKx08USOYCnyhquMLWHcD8CCnbxa/qaptitqf1QiMr8nNVV6ev4l3F6dQpVwoQy6vR9+2tYgKLXtPnpg8Cuy4doVzP8EHO6557WaxiEQC24B6qprmWjYMQFVHux4ffRu4Fufx0UFFNQuBJQLju77/dT/vfJvEjykHiAkPZkD72gzoUIeKUWX7+XRDqei45vWnhkqSJQLj61ZvO8ToRcl8sWEvYcEB9LmsFvd2qkf1WDdP7GK8z4c7rlkiMMYLkvYdZfSiFGavdm573dyyOsM616NBlWgvR2Y8wsc6rlkiMMaLdh7OYOx3KUxdvp2MrBy6N6nC8C7xtKrlW23Ixo18oOOaJQJjfMDBYyf5YMlvTFjyG2kZWbSrV4HhXepzRYNKxZsNzZQNRXZc6wVVW7il45olAmN8yLET2UxZvo33vkth75ETNK1Wjvu7xHNds6oE2mB2/qWgGdcq1neajkp4xjVLBMb4oBPZOcxevZN3F6WQsv8YdSpGcF/neG69tDqhQTagnd9xc8c1SwTG+LCcXOXLDXsYuTCZdTvTqBwdypAr6nJn29rWF8FfFTbjWvsHnPsK58ESgTGlgKryQ9IBRi1K4oekA5QLC+Lu9nUY1NH6Ivi1vB3XWt7pJIPzYInAmFJmzfbDjF6YzBc/7yE0KIDeCTW5t1M9apSP8HZoxptycyDg/JoNLREYU0ol7TvKu4tSmLV6Jwrc3KIaw7rEc7H1RTDnyBKBMaXcrsMZjP1uC1OWbyMjK4erGlfh/i7xtK5tfRFM8VgiMKaMOHSqL8KPv3H4eBZt61bg/i7xdL44zvoimCJZIjCmjDl2IpupK7Yz9rsUdqdl0qSq0xfh+kusL4IpmCUCY8qok9m5zF6zk9GLkklJPUbtihHc18npixAWbH0RzGmWCIwp43Jyla9+dvoirN2RRlx0KEMur8udbWsRHRbs7fCMD7BEYIyfUFWWJB9g1MJkvk/aT3RYEHe3r82gjnWpZH0R/JolAmP80E/bDzN6UTLzN+whJDCA3pfV5N4r6lGzgvVF8EfenKEsFhgLNAMUuEdVf8yzPgaYDNQCgoDXCprSMi9LBMacm+TUdN5dlMys1TvJVejRohrDOsfT8CLri+BPvJkIJgDfqepYEQkBIlT1cJ71TwMxqvqkiMQBm4GLVPVkYfu0RGDM+dmdlsH7323ho+XbOH4yh6saV3b1Rajg7dCMBxSVCNw2E4Lr134n4H0AVT2ZNwm4KBDtmrs4CjgIZLsrJmP8WdWYcJ65sQk/PHklj151MSu3HuK2UT9yx+gf+XbzPkpbM7EpOW6rEYhIS2AM8DPQAlgJ/ElVj+UpEw3MARoB0UBvVf1fAfsaCgwFqFWrVuutW7e6JWZj/Mnxk9lMXb6d91x9ERqf6ovQ7CKCAt07W5bxPK80DYlIArAU6Kiqy0RkBHBEVZ/NU6YX0BF4DIgHvgJaqOqRwvZrTUPGlKyT2bl86uqLkJx6jFoVIhjaqR69WtewvghliFeahoAdwA5VXeb6PB24NF+ZQcBMdSQBW3BqB8YYDwkJCuD2hJp89WhnRvdrTfmIYJ6ZvZ7LX/6WUQuTOZqZ5e0QjZu5LRGo6h5gu4icmmutG04zUV7bXMsRkSpAQyDFXTEZYwoXECBc2+wiZj/QkY+GtKVx1Whenr+JDi99wyvzN5F69IS3QzRu4u6nhlriPD4agnOBHwT0BlDV0SJSDfgAqAoI8JKqTi5qn9Y0ZIznrNuRxqhFScxb7/RFuCOhJkM7WV+E0sg6lBljLkhKajrvLkph5uod5Crc1Lwqw7rE0+iict4OzRSTJQJjTInYk5bJ+9+n8OEypy/ClY0qM7xLPAl1rC+Cr7NEYIwpUYePn2Tij1sZ/8MWDh3P4rI65bm/SzxdG1a2eRF8lCUCY4xbHD+ZzbQV23lvcQq70jJpdFE093eJ54ZLqlpfBB9jicAY41ZZObl8umYXoxclk7QvnZoVwhnaKZ7brS+Cz7BEYIzxiNxc5euNexm5MJk12w9TKSqUey6vQ792tSln8yJ4lSUCY4xHqSpLUw4ycmES3/26n+jQIPq1r82gjnWoHB3m7fD8kiUCY4zXrN+ZxqiFyXy+fjfBgQHckVCDoVfEU6ui9UXwJEsExhiv27L/GGMWJzNj5U6yc3O5sXk1Ol8cR724SOrFRRETbk1H7mSJwBjjM/YeyeT977fw4dKtHDuZ8/vySlGh1IuLJD4uknqVooiv7Pxbo3y4PYFUAiwRGGN8zsnsXLYdPE5Kajop+4+RvM/5NyU1nUPHTw90Fxwo1K4YSb1KTs0hPu70v7ERIV78C0qXohJBkKeDMcYYcEY9rV85ivqVo/6w7tCxk6TsTyc59RjJqemkuP79dvM+snJO/3itEBniShCRxMdFUS8uinpxkdSqEEGw1SKKzRKBMcbnlI8MoXVkhT9Mo5mdk8v2QxmkpKb/niBSUo/xzaZ9fJy44/dyQQFCrQoReWoQTi2iXqVIKkSGWO/nfCwRGGNKjaDAAOpWiqRupUi6Na5yxrq0jCynmSlPLSJlfzqLf0nlZE7u7+ViwoN/b16qd+p+RFwktStGEhLkn7UISwTGmDIhJjyYVrXK06pW+TOW5+QqOw9lkHyqFuG6D7H4l1SmrzxdiwgMEGqWD/+95nAqUcTHRVEpqmzXIiwRGGPKtMAAoVbFCGpVjKBro8pnrDuamfV7zeFUM1Nyajo/JO3nRPbpWkR0WJDTzFTpdDNTfFwUtStGlIkhNNyaCEQkFmdimmaAAveo6o/5ynQB3gCCgf2q2tmdMRljzCnRYcG0qBlLi5qxZyzPzVV2pWWQnHrs9+amlP3p/JhygJmrd/5eTgRqlA+nXqWoPAnCqUVUjg4tNbUId9cIRgDzVbWXiIQAZ3QldCWKkcC1qrpNRCoXtBNjjPGkgAChRvkIapSPoPPFcWesO3Yimy37896HcJLF8i0Hycg63S8iKjSIumc80eTcj6hbKZLwEN+qRbgtEYhIDNAJGAigqieBk/mK3Ykzef02V5l97orHGGNKQmRoEM2qx9CseswZy3NzlT1HMs9oakpOTSfxt0N8umbXGWWrx4b/IUHUi4ukakyYV2oR7qwR1AVSgfEi0gJYCfxJVY/lKXMxECwiC4FoYISqTsy/IxEZCgwFqFWrlhtDNsaY8xMQIFSLDadabDiXN6h0xrqMkzls2Z/3XoRz0/qTxO1n9K4ODw4841HXU8mibqVIIkPdd7l2W89iEUkAlgIdVXWZiIwAjqjqs3nKvA0kAN2AcOBH4AZV/aWw/VrPYmNMWaGq7Dt64ow+EU5HunR2HMog7+W5akwYgy+vy5Ar6p3XsbzVs3gHsENVl7k+Twf+UkCZA65awjERWQy0AApNBMYYU1aICFXKhVGlXBgd4s+sRWRm5bD1QJ4hOFLTiYsOdUscbksEqrpHRLaLSENV3Yzzq//nfMU+Bd4WkSAgBGgLvO6umIwxprQICw6k4UXRNLwo2u3HcvdTQw8BH7qeGEoBBonIMABVHa2qG0VkPrAWyAXGqup6N8dkjDEmDxt91Bhj/EBR9wj8c2ANY4wxv7NEYIwxfs4SgTHG+DlLBMYY4+csERhjjJ+zRGCMMX6u1D0+KiKpwNbz3LwSsL8EwykpvhoX+G5sFte5sbjOTVmMq7aqxhW0otQlggshIomFPUfrTb4aF/hubBbXubG4zo2/xWVNQ8YY4+csERhjjJ/zt0QwxtsBFMJX4wLfjc3iOjcW17nxq7j86h6BMcaYP/K3GoExxph8LBEYY4yfK5OJQESuFZHNIpIkIvlnRUNEQkVkmmv9MhGp4yNxDRSRVBFZ43oN8VBc40Rkn4gUOBeEON50xb1WRC71kbi6iEhanvP1nAdiqiki34rIzyKyQUT+VEAZj5+vYsbl8fPlOm6YiCwXkZ9csf29gDIe/04WMy5vfScDRWS1iMwtYF3JnytVLVMvIBBIBurhzHr2E9AkX5nhwGjX+z7ANB+JayDwthfOWSfgUmB9IeuvB+YBArQDlvlIXF2AuR4+V1WBS13vo3GmVc3/39Hj56uYcXn8fLmOK0CU630wsAxol6+MN76TxYnLW9/Jx4CPCvrv5Y5zVRZrBG2AJFVNUdWTwFTg5nxlbgYmuN5PB7qJiPhAXF6hqouBg0UUuRmYqI6lQKyIVPWBuDxOVXer6irX+6PARqB6vmIeP1/FjMsrXOch3fUx2PXK/5SKx7+TxYzL40SkBnADMLaQIiV+rspiIqgObM/zeQd//EL8XkZVs4E0oKIPxAVwm6s5YbqI1HRzTMVV3Ni9ob2raj9PRJp68sCuKnkrnF+SeXn1fBURF3jpfLmaOtYA+4CvVLXQc+bB72Rx4gLPfyffAJ7Amb63ICV+rspiIijNPgPqqGpz4CtOZ31TsFU446e0AN4CZnvqwCISBcwAHlHVI5467tmcJS6vnS9VzVHVlkANoI2INPPUsYtSjLg8+p0UkRuBfaq60p3Hya8sJoKdQN6sXcO1rMAyIhIExAAHvB2Xqh5Q1ROuj2OB1m6OqbiKc049TlWPnKraq+rnQLCIVHL3cUUkGOdi+6GqziygiFfO19ni8tb5yhfDYeBb4Np8q7zxnTxrXF74TnYEeojIbzjNx1eKyOR8ZUr8XJXFRLACaCAidUUkBOdmypx8ZeYAA1zvewHfqOvOizfjyteO3AOnndcXzAHudj0N0w5IU9Xd3g5KRC461TYqIm1w/n9268XDdbz3gY2q+t9Cinn8fBUnLm+cL9ex4kQk1vU+HOgObMpXzOPfyeLE5envpKo+pao1VLUOzjXiG1Xtl69YiZ+roAvZ2BeparaIPAh8gfOkzjhV3SAiLwCJqjoH5wszSUSScG5G9vGRuB4WkR5Atiuuge6OC0BEpuA8UVJJRHYAf8O5cYaqjgY+x3kSJgk4Dgzykbh6AfeLSDaQAfTxQELvCPQH1rnalgGeBmrlicsb56s4cXnjfIHzRNMEEQnEST4fq+pcb38nixmXV76T+bn7XNkQE8YY4+fKYtOQMcaYc2CJwBhj/JwlAmOM8XOWCIwxxs9ZIjDGGD9nicAYDxJnBNA/jChpjDdZIjDGGD9nicCYAohIP9dY9WtE5F3X4GTpIvK6a+z6BSIS5yrbUkSWugYmmyUi5V3L64vI165B3laJSLxr91GuAcw2iciHHhj51pgiWSIwJh8RaQz0Bjq6BiTLAe4CInF6dzYFFuH0dAaYCDzpGphsXZ7lHwLvuAZ56wCcGmaiFfAI0ARnfoqObv+jjClCmRtiwpgS0A1ncLEVrh/r4TjDFOcC01xlJgMzRSQGiFXVRa7lE4BPRCQaqK6qswBUNRPAtb/lqrrD9XkNUAf43v1/ljEFs0RgzB8JMEFVnzpjociz+cqd7/gsJ/K8z8G+h8bLrGnImD9aAPQSkcoAIlJBRGrjfF96ucrcCXyvqmnAIRG5wrW8P7DINUvYDhHp6dpHqIhEePSvMKaY7JeIMfmo6s8i8gzwpYgEAFnAA8AxnMlLnsFpKurt2mQAMNp1oU/h9Gij/YF3XSNHZgG3e/DPMKbYbPRRY4pJRNJVNcrbcRhT0qxpyBhj/JzVCIwxxs9ZjcAYY/ycJQJjjPFzlgiMMcbPWSIwxhg/Z4nAGGP83P8DsbSqDW5xuDMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('lose')\n",
        "plt.title('Plot of loss')\n",
        "x = range(0,5)\n",
        "y1 = h.history['loss']\n",
        "y2 = h.history['val_loss']\n",
        "plt.plot(x,y1)\n",
        "plt.plot(x,y2)\n",
        "plt.savefig('loss_plot.png')"
      ],
      "id": "38fdcd76"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2ec685a"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(h.history,open(\"history_1\",'wb'))"
      ],
      "id": "f2ec685a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "defca490-1c11-4d44-80ee-c5b0b4c8b923"
      },
      "outputs": [],
      "source": [
        "model.save_weights('model_with_bidef_attention_p'+str(max_len_context)+'_q'+str(max_len_question))"
      ],
      "id": "defca490-1c11-4d44-80ee-c5b0b4c8b923"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "6797f7c3",
        "outputId": "22c2c703-5b18-4aff-87a5-a693d735b333"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-65d1a9b3b181>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_40.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/node.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(self, make_node_key, node_conversion_map)\u001b[0m\n\u001b[1;32m    205\u001b[0m                       \u001b[0;34m' was passed non-JSON-serializable arguments. '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                       \u001b[0;34m'Arguments had types: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                       \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwarg_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. They cannot be serialized out '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m                       'when saving the model.')\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Layer tf.math.multiply_1 was passed non-JSON-serializable arguments. Arguments had types: {'y': <class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>, 'name': <class 'NoneType'>}. They cannot be serialized out when saving the model."
          ]
        }
      ],
      "source": [
        "model.save('model_40.h5')"
      ],
      "id": "6797f7c3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04313af7-845d-4842-a1ca-dda40d542e14"
      },
      "source": [
        "# Performance of Model"
      ],
      "id": "04313af7-845d-4842-a1ca-dda40d542e14"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25a3b0fa-faf6-4ec8-87ec-105e2aa4253d"
      },
      "outputs": [],
      "source": [
        "f = open('./drive/MyDrive/data/dev-v2.0.json','r')\n",
        "test_data = json.load(f)"
      ],
      "id": "25a3b0fa-faf6-4ec8-87ec-105e2aa4253d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3eddf41-840f-476a-81d7-edd0518cde75",
        "outputId": "c0eaf708-837a-45b3-c788-d162a09aa69c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Preprocessing: 100%|██████████| 35/35 [00:07<00:00,  4.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number Total examples: 4820\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test_exmpl,test_max_len_context,test_max_len_question = preprocessing(test_data)"
      ],
      "id": "b3eddf41-840f-476a-81d7-edd0518cde75"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdfc7747-461b-4520-b4bf-00aea0206cde",
        "outputId": "33402788-615d-4f59-8294-49c8b6595d63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (64, 250) for input KerasTensor(type_spec=TensorSpec(shape=(64, 250), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (1, 250).\n",
            "WARNING:tensorflow:Model was constructed with shape (64, 30) for input KerasTensor(type_spec=TensorSpec(shape=(64, 30), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (1, 30).\n"
          ]
        }
      ],
      "source": [
        "test_m = np.array(test_exmpl[:])\n",
        "test_con = sentences_to_indices(test_m[:,0],word2idx,max_len_context)\n",
        "test_qe = sentences_to_indices(test_m[:,1],word2idx,max_len_question)\n",
        "y1 = np.array(op(test_m[:,3]))\n",
        "prediction = model.predict([test_con,test_qe],batch_size=1)"
      ],
      "id": "fdfc7747-461b-4520-b4bf-00aea0206cde"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d46a566-9ebd-4f39-bc94-abb7ae187c29"
      },
      "outputs": [],
      "source": [
        "def smart_span(prediction,con_len):\n",
        "    prediction[:,0,:] = tf.nn.softmax(prediction[:,0,:],axis=1)\n",
        "    prediction[:,1,:] = tf.nn.softmax(prediction[:,1,:],axis=1)\n",
        "\n",
        "    b = prediction.shape[0]\n",
        "    start = np.zeros(b,dtype='int64')\n",
        "    end = np.zeros(b,dtype='int64')\n",
        "    max_prob = np.zeros(b)\n",
        "\n",
        "    for i in range(b):\n",
        "        maxprod = 0\n",
        "        chosen_start = 0\n",
        "        chosen_end = 0\n",
        "\n",
        "        for j in range(con_len[i]-16):\n",
        "            end_sub = prediction[i,1,j:j+16]\n",
        "            end_max_prob = np.amax(end_sub)\n",
        "            end_in = np.argmax(end_sub)\n",
        "\n",
        "            start_prob = prediction[i,0,j]\n",
        "            prod = start_prob*end_max_prob\n",
        "\n",
        "            if prod>maxprod:\n",
        "                maxprod=prod\n",
        "                chosen_start = j\n",
        "                chosen_end = chosen_start + end_in\n",
        "        start[i] = chosen_start\n",
        "        end[i] = chosen_end\n",
        "    return start,end"
      ],
      "id": "4d46a566-9ebd-4f39-bc94-abb7ae187c29"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71590d81-a76c-4675-90e8-020b2798af76"
      },
      "outputs": [],
      "source": [
        "p1 = prediction[1]\n",
        "#p1 = tf.nn.softmax(p1,0)\n",
        "ans = tf.math.argmax(p1,axis=1)\n",
        "l = ans.numpy()"
      ],
      "id": "71590d81-a76c-4675-90e8-020b2798af76"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adf9a387-992c-49e3-a633-fc411d9834c1"
      },
      "outputs": [],
      "source": [
        "con_len = []\n",
        "con_text = test_m[:,0]\n",
        "for i in range(con_text.shape[0]):\n",
        "    context_tokens = tokenize(con_text[i])\n",
        "    con_len.append(len(context_tokens))\n",
        "start,end = smart_span(prediction,con_len)"
      ],
      "id": "adf9a387-992c-49e3-a633-fc411d9834c1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c005f3dc-76a4-4311-bb4c-9e273c22252c"
      },
      "outputs": [],
      "source": [
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
      ],
      "id": "c005f3dc-76a4-4311-bb4c-9e273c22252c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34540cea-08d9-42b5-b820-619b85192a94"
      },
      "outputs": [],
      "source": [
        "def f1_score(prediction, ground_truth):\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0,0,0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1,precision,recall"
      ],
      "id": "34540cea-08d9-42b5-b820-619b85192a94"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "112250e7-84ca-47d1-87e3-c477c19a05c7"
      },
      "outputs": [],
      "source": [
        "def exact_match_score(prediction, ground_truth):\n",
        "    return (normalize_answer(prediction) == normalize_answer(ground_truth))"
      ],
      "id": "112250e7-84ca-47d1-87e3-c477c19a05c7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca31031c-4c82-4b2b-9c8f-91b71cb16ac1"
      },
      "outputs": [],
      "source": [
        "predicted_ans = []\n",
        "for i in range(con_text.shape[0]):\n",
        "    context_tokens = tokenize(con_text[i])\n",
        "    ans=\"\"\n",
        "    for w in context_tokens[start[i]:end[i]+1]:\n",
        "        ans+=w\n",
        "        ans+=' '\n",
        "    predicted_ans.append(ans)\n",
        "predicted_ans = predicted_ans"
      ],
      "id": "ca31031c-4c82-4b2b-9c8f-91b71cb16ac1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a77b21bb-12fb-4a93-8542-71008aab98a2",
        "outputId": "67891a91-66e8-4125-e08f-071c72f9fdea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 score: 21.598904497343792\n",
            "EM score: 11.763485477178422\n",
            "Precision score: 21.682572355030896\n",
            "Recall score: 27.193539113345288\n"
          ]
        }
      ],
      "source": [
        "crct_ans = test_m[:,2]\n",
        "f1=0\n",
        "em=0\n",
        "prec=0\n",
        "recall=0\n",
        "for i in range(crct_ans.shape[0]):\n",
        "    t1,t2,t3 = f1_score(predicted_ans[i], crct_ans[i])\n",
        "    f1+=t1\n",
        "    prec+=t2\n",
        "    recall+=t3\n",
        "    if exact_match_score(normalize_answer(predicted_ans[i]), normalize_answer(crct_ans[i])):\n",
        "        em+=1\n",
        "f1 = f1/crct_ans.shape[0]\n",
        "em = em/crct_ans.shape[0]\n",
        "prec=prec/crct_ans.shape[0]\n",
        "recall=recall/crct_ans.shape[0]\n",
        "print(\"F1 score: \"+str(100*f1))\n",
        "print(\"EM score: \"+str(100*em))\n",
        "print(\"Precision score: \"+str(100*prec))\n",
        "print(\"Recall score: \"+str(100*recall))"
      ],
      "id": "a77b21bb-12fb-4a93-8542-71008aab98a2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8843dd80-bf99-4dd8-a539-2f7e41dde5e4"
      },
      "source": [
        "# Test Model"
      ],
      "id": "8843dd80-bf99-4dd8-a539-2f7e41dde5e4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3846508-7d1c-4ac7-a62b-2ae13189bd8f"
      },
      "outputs": [],
      "source": [
        "def sen_2_ind(x,word2idx,max_len):\n",
        "    x_ind = np.zeros((1,max_len))\n",
        "    sentence_words = x.lower().split()\n",
        "    # Initialize j to 0\n",
        "    j = 0\n",
        "     # Loop over the words of sentence_words\n",
        "    for w in sentence_words:\n",
        "        # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
        "        if w in word2idx.keys():\n",
        "            x_ind[0,j] = word2idx[w]\n",
        "        else:\n",
        "            x_ind[0,j] = word2idx[b\"<unk>\"]\n",
        "            # Increment j to j + 1\n",
        "        j += 1\n",
        "    return x_ind\n",
        ""
      ],
      "id": "f3846508-7d1c-4ac7-a62b-2ae13189bd8f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb40fef6-b2dd-4b97-a797-77de7ece40bb"
      },
      "outputs": [],
      "source": [
        "def test_preprocessing(context,question):\n",
        "    context = context.replace(\"''\", '\" ')\n",
        "    context = context.replace(\"``\", '\" ')\n",
        "    context_tokens = tokenize(context)\n",
        "    if len(context_tokens)>250:\n",
        "        print(\"Please enter context of length <=100\")\n",
        "        return\n",
        "\n",
        "    question_tokens = tokenize(question)\n",
        "    if len(question_tokens)>30 or ('why' in question_tokens) or ('how' in question_tokens):\n",
        "        print(\"Please enter a valid question\")\n",
        "    test_ex = []\n",
        "    test_ex.append((' '.join(context_tokens), ' '.join(question_tokens)))\n",
        "    con = sen_2_ind(test_ex[0][0],word2idx,max_len_context)\n",
        "    qe = sen_2_ind(test_ex[0][1],word2idx,max_len_question)\n",
        "    return con,qe\n",
        ""
      ],
      "id": "cb40fef6-b2dd-4b97-a797-77de7ece40bb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bad24624-b654-4202-a064-21e499e29479"
      },
      "outputs": [],
      "source": [
        "def col_print(s):\n",
        "    print(\"\\033[34m\"+s+'\\033[0m')"
      ],
      "id": "bad24624-b654-4202-a064-21e499e29479"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66974429-424d-4189-aaa3-ea4bd4408b5c",
        "outputId": "b478ddc4-6366-44e0-e9d8-96148ed53abc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34mContext:\u001b[0m\n",
            " Prime numbers of this form are known as factorial primes. Other primes where either p + 1 or p − 1 is of a particular shape include the Sophie Germain primes (primes of the form 2p + 1 with p prime), primorial primes, Fermat primes and Mersenne primes, that is, prime numbers that are of the form 2p − 1, where p is an arbitrary prime. The Lucas–Lehmer test is particularly fast for numbers of this form. This is why the largest known prime has almost always been a Mersenne prime since the dawn of electronic computers.\n",
            "\u001b[34mQuestion:\u001b[0m\n",
            "Of what form are Mersenne primes?\n",
            "\u001b[34mPredicted ans:\u001b[0m\n",
            "factorial primes \n"
          ]
        }
      ],
      "source": [
        "con_file = open(\"./drive/MyDrive/data/Context.txt\",\"r\")\n",
        "qe_file = open(\"./drive/MyDrive/data/Question.txt\",\"r\")\n",
        "test_context = con_file.read()\n",
        "test_question = qe_file.read()\n",
        "#actual_ans = \"Robert Boyle\"\n",
        "c,q = test_preprocessing(test_context,test_question)\n",
        "prediction = model.predict([c,q],batch_size=1)\n",
        "\n",
        "con_tokens = tokenize(test_context)\n",
        "con_len.append(len(context_tokens))\n",
        "start,end = smart_span(prediction,con_len)\n",
        "ans=\"\"\n",
        "for w in con_tokens[start[0]:end[0]+1]:\n",
        "    ans+=w\n",
        "    ans+=' '\n",
        "col_print(\"Context:\")\n",
        "print(test_context)\n",
        "col_print(\"Question:\")\n",
        "print(test_question)\n",
        "#col_print(\"Correct answer:\")\n",
        "#print(actual_ans)\n",
        "col_print(\"Predicted ans:\")\n",
        "print(ans)"
      ],
      "id": "66974429-424d-4189-aaa3-ea4bd4408b5c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7297b36d-d4b9-4454-975d-d686bccdfb23"
      },
      "source": [
        "# References"
      ],
      "id": "7297b36d-d4b9-4454-975d-d686bccdfb23"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f31ac6d5-3159-4479-bba5-de34dff834a4"
      },
      "source": [
        "https://arxiv.org/abs/1611.01603 <br>\n",
        "https://towardsdatascience.com/nlp-building-a-question-answering-model-ed0529a68c54"
      ],
      "id": "f31ac6d5-3159-4479-bba5-de34dff834a4"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}